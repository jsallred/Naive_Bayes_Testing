{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04d4b94-2bae-429c-aaf5-f963af19dd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.69230769 0.66153846 0.69846154 0.73538462 0.68      ]\n",
      "Mean CV Accuracy: 0.6935384615384617\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "df = pd.read_csv('BABE_scraped.csv')\n",
    "df['content'] = df['content'].str.lower()  # Convert text to lowercase\n",
    "df.dropna(subset=['content'], inplace=True)  # Drop rows with missing values in the 'content' column\n",
    "\n",
    "# Step 2: Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=500, stop_words='english')  # Reduced max features\n",
    "X_text = vectorizer.fit_transform(df['content'])\n",
    "y = df['type_class']\n",
    "\n",
    "# Step 3: Combine text features\n",
    "X = X_text\n",
    "\n",
    "# Step 4: Initialize Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Step 5: Evaluate using cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Optional: Print classification report for detailed evaluation\n",
    "# Since the model is being evaluated using cross-validation, a separate test set isn't needed.\n",
    "# You can uncomment the following lines if you still want to see the classification report.\n",
    "\n",
    "# y_pred = cross_val_predict(clf, X, y, cv=cv)\n",
    "# print(\"Classification Report for Cross-Validation:\")\n",
    "# print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176bff5-85f8-4cf7-96c0-70f37ce5d597",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- We reduced the max features for the TF-IDF vectorizer to 500 to reduce dimensionality.\n",
    "- We removed domain names as features to simplify the model.\n",
    "- We used stratified k-fold cross-validation to provide a more reliable estimate of the model's performance.\n",
    "- We evaluated the model using cross-validation and printed the mean accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ebadc-f7c6-42ec-ba0f-bef214afc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "df = pd.read_csv('BABE_scraped.csv')\n",
    "df['content'] = df['content'].str.lower()  # Convert text to lowercase\n",
    "df.dropna(subset=['content'], inplace=True)  # Drop rows with missing values in the 'content' column\n",
    "\n",
    "# Step 2: Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_text = vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Additional Features\n",
    "# Content length\n",
    "df['content_length'] = df['content'].apply(len)\n",
    "\n",
    "# Sentiment score using TextBlob\n",
    "df['sentiment_score'] = df['content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Combine features\n",
    "X = pd.concat([pd.DataFrame(X_text.toarray()), df[['content_length', 'sentiment_score']]], axis=1)\n",
    "y = df['type_class']\n",
    "\n",
    "# Convert integer column names to strings\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Filter out rows in X without corresponding target values in y\n",
    "X = X.iloc[:len(y), :]\n",
    "\n",
    "# Drop rows with missing values in X\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Reset y index to match filtered X\n",
    "y = y[X.index]\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize Logistic Regression classifier\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Step 5: Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate using cross-validation\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Step 7: Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ebe54d-5d28-492c-8b65-011a6bf0f012",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- We included additional features such as content length and sentiment score using TextBlob.\n",
    "- We used Logistic Regression as the classifier.\n",
    "- We evaluated the model using cross-validation and printed the mean accuracy score.\n",
    "- We evaluated the model on the test set and printed the classification report for detailed performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da663d4d-36af-426f-be12-694d476f120b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
